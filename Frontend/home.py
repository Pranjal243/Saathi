import streamlit as st
import speech_recognition as sr
import requests
from gtts import gTTS
import io

# Speech-to-text function
def transcribe_audio():
    recognizer = sr.Recognizer()
    with sr.Microphone(device_index=0) as source:
        st.info("Listening... Speak now.")
        try:
            audio = recognizer.listen(source, timeout=5)
            text = recognizer.recognize_google(audio,language='ne-NP')
            return text
        except sr.UnknownValueError:
            return "Sorry, I could not understand that."
        except sr.RequestError as e:
            return f"Error: {e}"
        
#translate question to english
def translate(question,src,target):
    translate_api="http://127.0.0.1:5000/translate"
    data= {
        "text": question,
        "source_language": src,
        "target_language": target
    }  
    try:
        response = requests.post(translate_api, json=data)
        response.raise_for_status()  # Raise an exception for 4xx or 5xx responses
        return response.json()  # Return the JSON response from the API
    except requests.exceptions.RequestException as e:
        return {"error": f"API request failed: {e}"}
    
#translate question to english
def chat(question_eng):
    translate_api="http://127.0.0.1:5000/qa"
    data = {
    "question": question_eng
    }   
    try:
        response = requests.post(translate_api, json=data)
        response.raise_for_status()  # Raise an exception for 4xx or 5xx responses
        return response.json()  # Return the JSON response from the API
    except requests.exceptions.RequestException as e:
        return {"error": f"API request failed: {e}"}

# Function to generate audio
def generate_audio(text):
    lang='ne'
    tts = gTTS(text=text, lang=lang)
    audio_buffer = io.BytesIO()
    tts.write_to_fp(audio_buffer)
    audio_buffer.seek(0)
    return audio_buffer

# Streamlit UI
st.title("‡§§‡§™‡§æ‡§á‡§Å‡§ï‡•ã ‡§∏‡§æ‡§•‡•Ä")
st.write("‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§§‡§≤‡§ï‡•ã ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§¨‡§ü‡§® ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ó‡§∞‡•á‡§∞ ‡§∏‡•ã‡§ß‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç‡•§")

# Chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Input: Voice button
if st.button("üéôÔ∏è Tap to Speak"):
    question = transcribe_audio()
    if question:
        st.session_state.messages.append({"user": True, "text": question})
        answer = chat(question)
        print(answer)
        response = f"{answer['answer']}"
        st.session_state.messages.append({"user": False, "text": response})

        # Play the audio file
        # audio_file = generate_audio(answer_org['data'])
        # st.audio(audio_file, format="audio/mp3")

for msg in st.session_state.messages:
    if msg["user"]:
        # Display user messages on the left side with a unique color
        st.markdown(f"""
            <div style="background-color: #E1F5FE; padding: 10px; margin: 5px; border-radius: 10px; max-width: 70%; float: left;">
                <strong>You:</strong> {msg['text']}
            </div>
            """, unsafe_allow_html=True)
    else:
        # Display bot messages on the right side with a different color
        st.markdown(f"""
            <div style="background-color: #FFEBEE; padding: 10px; margin: 5px; border-radius: 10px; max-width: 70%; float: right;">
                <strong>Bot:</strong> {msg['text']}
            </div>
            """, unsafe_allow_html=True)

# Audio Play Button for Bot Response
if "messages" in st.session_state and len(st.session_state.messages) > 0:
    last_message = st.session_state.messages[-1]
    if not last_message["user"]:  # If last message is from the bot
        audio_buffer = generate_audio(last_message["text"])
        st.audio(audio_buffer, format="audio/mp3")
